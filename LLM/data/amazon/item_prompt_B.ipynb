{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open(\"./handled/item2attributes_B.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2847"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2847/2847 [00:00<00:00, 492602.76it/s]\n"
     ]
    }
   ],
   "source": [
    "example_dict = {}\n",
    "for item_dict in tqdm(data.values()):\n",
    "    example_dict.update(item_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2847/2847 [00:00<00:00, 696522.60it/s]\n"
     ]
    }
   ],
   "source": [
    "id_map = json.load(open(\"./handled/id_map.json\", \"r\"))[\"item_dict\"][\"1\"][\"str2id\"]\n",
    "title_data = {}\n",
    "for key, value in tqdm(data.items()):\n",
    "    title_data[id_map[key]] = value[\"title\"][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = []\n",
    "for id in range(1, len(id_map)+1):\n",
    "    if id not in title_data.keys():\n",
    "        title_list.append(\"no name\")\n",
    "    else:\n",
    "        title_list.append(title_data[id])\n",
    "\n",
    "assert len(title_list) == len(id_map)\n",
    "\n",
    "with open(\"./handled/title_B.pkl\", \"wb\") as f:\n",
    "    pickle.dump(title_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of items that do not have name: 5\n"
     ]
    }
   ],
   "source": [
    "# the number of items that do not have name\n",
    "print(\"the number of items that do not have name: {}\".format(len(id_map.values()) - len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['category', 'tech1', 'description', 'fit', 'title', 'also_buy', 'tech2', 'brand', 'feature', 'rank', 'also_view', 'main_cat', 'similar_item', 'date', 'price', 'asin', 'imageURL', 'imageURLHighRes', 'details'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BRENDA BLETHYN is Vera Stanhope, a sharp detective with a messy life Blethyn is wonderful. ???The Times (U.K.) A first-rate mystery series ???Library Journal Captivating ???Library Bookwatch Classy crime drama ???The Daily Telegraph (U.K.) Two-time Oscar nominee Brenda Blethyn (Pride & Prejudice, Secrets & Lies) returns as Vera Stanhope???a police detective with a disheveled exterior, a sharp tongue, and an uncanny ability to solve crimes. Tough, dedicated, and more than a little irreverent, DCI Stanhope is assisted by her long-suffering sergeant, Joe Ashworth (David Leon, RocknRolla); DC Kenny Lockhart (Jon Morrison, High Times); and forensic pathologist Billy Cartwright (Paul Ritter, The Eagle). Inspired by Ann Cleeves???s bestselling mysteries, Vera is set in the Northumberland of the original books. In four new feature-length dramas, Stanhope delves into a world of shadows and suppressed passions where everyone has something to hide. Guest stars include Rose Leslie (Game of Thrones), Julie Graham (Bonekickers), Phyllis Logan (Downton Abbey), and Judy Parfitt (Girl with a Pearl Earring).'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_dict[\"description\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attri(item_str, attri, item_info):\n",
    "\n",
    "    if attri not in item_info.keys() or len(item_info[attri]) > 100:\n",
    "        new_str = item_str.replace(f\"<{attri.upper()}>\", \"unknown\")\n",
    "    else:\n",
    "        new_str = item_str.replace(f\"<{attri.upper()}>\", str(item_info[attri]))\n",
    "\n",
    "    return new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feat(item_str, feat, item_info):\n",
    "\n",
    "    if feat not in item_info.keys():\n",
    "        return \"\"\n",
    "    \n",
    "    assert isinstance(item_info[feat], list)\n",
    "    feat_str = \"\"\n",
    "    for meta_feat in item_info[feat]:\n",
    "        feat_str = feat_str + meta_feat + \"; \"\n",
    "    new_str = item_str.replace(f\"<{feat.upper()}>\", feat_str)\n",
    "\n",
    "    if len(new_str) > 128: # avoid exceed the input length limitation\n",
    "        return new_str[:128]\n",
    "\n",
    "    return new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"The movies and TV item has following attributes: \\n name is <TITLE>; brand is <BRAND>; price is <PRICE>, rating is <DATE>, price is <PRICE>. \\n\"\n",
    "feat_template = \"The item has following features: <CATEGORY>. \\n\"\n",
    "desc_template = \"The item has following descriptions: <DESCRIPTION>. \\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2847/2847 [00:00<00:00, 107392.47it/s]\n"
     ]
    }
   ],
   "source": [
    "item_data = {}\n",
    "for key, value in tqdm(data.items()):\n",
    "    item_str = copy.deepcopy(prompt_template)\n",
    "    item_str = get_attri(item_str, \"title\", value)\n",
    "    item_str = get_attri(item_str, \"brand\", value)\n",
    "    item_str = get_attri(item_str, \"date\", value)\n",
    "    # item_str = get_attri(item_str, \"rank\", value)\n",
    "    item_str = get_attri(item_str, \"price\", value)\n",
    "\n",
    "    feat_str = copy.deepcopy(feat_template)\n",
    "    feat_str = get_feat(feat_str, \"category\", value)\n",
    "    desc_str = copy.deepcopy(desc_template)\n",
    "    desc_str = get_feat(desc_str, \"description\", value)\n",
    "    \n",
    "    item_data[key] = item_str + feat_str + desc_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362.1022128556375"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_list = []\n",
    "for item_str in item_data.values():\n",
    "    len_list.append(len(item_str))\n",
    "np.mean(len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(item_data, open(\"./handled/item_str_B_truncate.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to jsonline\n",
    "def save_data(data_path, data):\n",
    "    '''write all_data list to a new jsonl'''\n",
    "    with jsonlines.open(\"./handled/\"+ data_path, \"w\") as w:\n",
    "        for meta_data in data:\n",
    "            w.write(meta_data)\n",
    "\n",
    "id_map = json.load(open(\"./handled/id_map.json\", \"r\"))[\"item_dict\"][\"1\"][\"str2id\"]\n",
    "json_data = []\n",
    "for key, value in item_data.items():\n",
    "    json_data.append({\"input\": value, \"target\": \"\", \"item\": key, \"item_id\": id_map[key]})\n",
    "\n",
    "json_data = sorted(json_data, key=lambda x: x[\"item_id\"])\n",
    "save_data(\"item_str_B_truncate.jsonline\", json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(prompt):\n",
    "    url = \"https://chatapi.littlewheat.com/v1/embeddings\"\n",
    "\n",
    "    payload = json.dumps({\n",
    "    \"model\": \"text-embedding-3-large\",\n",
    "    \"input\": prompt\n",
    "    })\n",
    "    headers = {\n",
    "    'Authorization': 'Bearer sk-L7XOrSKuS5sfsoNYkmj3rSyLahhwBdtG1iefI8xTXFaJ8Oh0',\n",
    "    'User-Agent': 'Apifox/1.0.0 (https://apifox.com)',\n",
    "    'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    re_json = json.loads(response.text)\n",
    "\n",
    "    return re_json[\"data\"][0][\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2847/2847 [00:00<00:00, 1365486.96it/s]\n"
     ]
    }
   ],
   "source": [
    "value_list = []\n",
    "\n",
    "for key, value in tqdm(item_data.items()):\n",
    "    if len(value) > 4096:\n",
    "        value_list.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"./handled/item_emb_B.pkl\"):    # check whether some item emb exist in cache\n",
    "    item_emb = pickle.load(open(\"./handled/item_emb_B.pkl\", \"rb\"))\n",
    "else:\n",
    "    item_emb = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 1114/2847 [55:59<1:27:06,  3.02s/it]\n",
      "100%|██████████| 2847/2847 [1:13:28<00:00,  1.55s/it]  \n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "while 1:    # avoid broken due to internet connection\n",
    "    # 如果数据全部跑完，退出循环\n",
    "    if len(item_emb) == len(item_data):\n",
    "        break\n",
    "        \n",
    "    try:\n",
    "        for key, value in tqdm(item_data.items()):\n",
    "            if key not in item_emb.keys():\n",
    "                # 截断过长文本\n",
    "                if len(value) > 4096:\n",
    "                    value = value[:4095]\n",
    "                \n",
    "                # 获取响应\n",
    "                item_emb[key] = get_response(value)\n",
    "                \n",
    "                # 【修改点】每隔 10 次存储一次\n",
    "                if count % 10 == 0:\n",
    "                    pickle.dump(item_emb, open(\"./handled/item_emb_A.pkl\", \"wb\"))\n",
    "                \n",
    "                count += 1\n",
    "                \n",
    "    except:\n",
    "        # 如果报错崩溃，依然执行一次保存，作为兜底\n",
    "        pickle.dump(item_emb, open(\"./handled/item_emb_A.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_map = json.load(open(\"./handled/id_map.json\", \"r\"))[\"item_dict\"][\"1\"][\"id2str\"]\n",
    "emb_list = []\n",
    "for id in range(1, len(id_map)+1):\n",
    "    try:    # 有一个物品没有属性，给其赋0向量\n",
    "        meta_emb = item_emb[id_map[str(id)]]\n",
    "    except:\n",
    "        meta_emb = [0] * len(list(item_emb.values())[0])\n",
    "    emb_list.append(meta_emb)\n",
    "\n",
    "emb_list = np.array(emb_list)\n",
    "pickle.dump(emb_list, open(\"./handled/itm_emb_np_B.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保LLM embedding和物品的数量是相同的\n",
    "assert len(emb_list) == len(id_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
